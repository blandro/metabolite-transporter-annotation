{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deep TMHMM from fasta**\n",
    "\n",
    "Just a quick split up of all fasta-seqs from TCDB, as well as trying out TMHMM on a batch. Just to get a view of what it does.\n",
    "\n",
    "Spoiler: It shows transmembrane segments, that's basically it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-27 11:10:26,348 | INFO : Loaded project DTU/DeepTMHMM:1.0.42\n"
     ]
    }
   ],
   "source": [
    "import biolib\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "from IPython.display import Image\n",
    "deeptmhmm = biolib.load('DTU/DeepTMHMM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***First of - Submitting a large batch at once***\n",
    "\n",
    "*TMRs.gff3*: This file contains transmembrane region annotations in GFF3 format.        \n",
    "*predicted_topologies.3line*: A plain-text file with the predicted topology for each protein (cytoplasmic, extracellular, transmembrane).                                                   \n",
    "*deeptmhmm_results.md*: A markdown file summarizing the results.\n",
    "\n",
    "Divide the large FASTA-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_fasta(input_fasta, output_prefix, chunk_size):\n",
    "\n",
    "    os.makedirs(\"fasta_batches_split\", exist_ok=True)\n",
    "\n",
    "    fasta_sequences = SeqIO.parse(open(input_fasta), 'fasta')\n",
    "    batch_number = 1\n",
    "    sequences_in_batch = []\n",
    "    \n",
    "    for i, fasta in enumerate(fasta_sequences):\n",
    "        sequences_in_batch.append(fasta)\n",
    "        \n",
    "        if (i + 1) % chunk_size == 0:\n",
    "            \n",
    "            output_file = f\"fasta_batches_split/{output_prefix}_batch_{batch_number}.fasta\"\n",
    "            SeqIO.write(sequences_in_batch, output_file, \"fasta\")\n",
    "            sequences_in_batch = []\n",
    "            batch_number += 1\n",
    "    \n",
    "    if sequences_in_batch:\n",
    "        output_file = f\"fasta_batches_split/{output_prefix}_batch_{batch_number}.fasta\"\n",
    "        SeqIO.write(sequences_in_batch, output_file, \"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process each batch with DeepTMHMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_fasta_batches(output_prefix, batch_count):\n",
    "\n",
    "    os.makedirs(\"fasta_batches_processed\", exist_ok=True)\n",
    "\n",
    "    for batch_number in range(1, batch_count + 1):\n",
    "        \n",
    "        batch_file = f\"fasta_batches_split/{output_prefix}_batch_{batch_number}.fasta\"\n",
    "        print(f\"Processing {batch_file}...\")\n",
    "        deeptmhmm_job = deeptmhmm.cli(args=f\"--fasta {batch_file}\")\n",
    "        deeptmhmm_job.save_files(f\"fasta_batches_processed/{batch_number}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fasta = \"../TCDB_fasta.txt\"\n",
    "output_prefix = \"TCDB_fasta_split\"\n",
    "chunk_size = 50\n",
    "# 100-500 is reasonable for TCC\n",
    "\n",
    "split_fasta(input_fasta, output_prefix, chunk_size)\n",
    "\n",
    "batch_count = (len(list(SeqIO.parse(input_fasta, \"fasta\"))) + chunk_size - 1) // chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing fasta_batches_split/TCDB_fasta_split_batch_1.fasta...\n",
      "2024-09-27 11:11:27,080 | INFO : Cloud: Initializing\n",
      "2024-09-27 11:11:29,227 | INFO : Cloud: Pulling images...\n",
      "2024-09-27 11:11:29,229 | INFO : Cloud: Computing...\n",
      "2024-09-27 09:11:31,386 | INFO : Large input detected. Allocating dedicated capacity ...\n",
      "Running DeepTMHMM on 50 sequences...\n",
      "Step 1/4 | Loading transformer model...\n",
      "\n",
      "Step 2/4 | Generating embeddings for sequences...\n",
      "Generating embeddings: 100% 50/50 [00:06<00:00,  7.86seq/s]\n",
      "\n",
      "Step 3/4 | Predicting topologies for sequences in batches of 1...\n",
      "Topology prediction: 100% 50/50 [00:24<00:00,  2.05seq/s]\n",
      "\n",
      "Step 4/4 | Generating output...\n",
      "2024-09-27 11:16:19,871 | INFO : Cloud: Computation finished\n",
      "2024-09-27 09:16:19,689 | INFO : Done in 288.60 seconds\n",
      "2024-09-27 11:16:21,984 | INFO : Cloud: Result Ready\n",
      "2024-09-27 11:16:21,986 | INFO : Waiting for job 846b574b-6758-4885-8e13-cef1529b3643 to finish...\n",
      "2024-09-27 11:16:22,295 | INFO : Job 846b574b-6758-4885-8e13-cef1529b3643 has finished.\n",
      "2024-09-27 11:16:22,901 | INFO : Saving 3 files to fasta_batches_processed/1...\n"
     ]
    }
   ],
   "source": [
    "# process_fasta_batches(output_prefix, batch_count)\n",
    "process_fasta_batches(output_prefix, 1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
